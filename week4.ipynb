{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "def hello():\n",
    "    print(\"A functional hello.\")\n",
    "\n",
    "hello()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A functional hello.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def greet(name):\n",
    "    print(\"Hello \" + name + \"!\")\n",
    "\n",
    "greet(\"World\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def greet_default(name = \"You\"):\n",
    "    print(\"Hello \" + name + \"!\")\n",
    "greet_default()\n",
    "greet_default(\"Lois\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello You!\n",
      "Hello Lois!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def make_greeting(firstName, lastName):\n",
    "    return(\"Hello \" + firstName + \" \" + lastName + \"!\")\n",
    "    \n",
    "print(make_greeting(\"Clark\", \"Kent\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello Clark Kent!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def local_greeting():\n",
    "    name = \"Fred\"\n",
    "    print(\"Hi \" + name + \"!\")\n",
    "name = \"Barney\"\n",
    "local_greeting()\n",
    "print(\"Hi \" + name + \"!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hi Fred!\n",
      "Hi Barney!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# This program assumes you have completed exercise three, and we will be using the text file from that exercise in this demo. In the take home assignment, you will be combining the parts and making use of functions to structure a more complete text processing pipeline. The sample for processing, dogememe.txt, is available in the repository\n",
    "\n",
    "f = open('julietreviews.txt', 'r')\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "word_bag = text.split()\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Juliet', 'Takes', 'a', 'Breath,\\\\nplease', 'sign', 'up.\\\\n\\\\n\\\\n\\\\n\\\\nPopular', 'Answered', 'Questions\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nIs', 'this', 'book', 'appropriate', 'for', '13-14', 'year', 'old', '8th', 'graders?', 'We', 'have', 'students', 'requesting', 'novels', 'with', 'lesbian', 'protagonists', 'and', 'unfortunately,', 'I', 'can&#39;t', 'find', 'many', 'that', 'seem', 'appropriate', 'for', 'my', 'students.', 'Mild', 'cursing,', 'but', 'I', 'don&#39;t', 'want', 'it', 'to', 'be', 'focused', 'solely', 'on', 'the', 'sexual', 'identity', 'of', 'the', 'character.\\\\n\\\\n\\\\n\\\\n\\\\nlike\\\\n\\\\n\\\\n\\\\n3', 'years', 'ago\\\\n\\\\n\\\\nSee', 'all', '5', 'answers\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nTaiwo', '|', 'A', 'Lifestyle', 'Nerd', '\\\\n\\\\n\\\\nThere&apos;s', 'not', 'a', 'lot', 'of', 'sexuality', 'in', 'the', 'book.', 'A', 'little', 'kissing', 'and', 'very', 'little', 'sex', 'but', 'that', 'aspect', 'is', 'very', 'little.', 'The', 'romance', 'is', 'actually', 'cute.', 'Most', \"im\\\\xe2\\\\x80\\\\xa6moreThere\\\\'s\", 'not', 'a', 'lot', 'of', 'sexuality', 'in', 'the']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "text = text.lower()\n",
    "word_bag = text.split()\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['juliet', 'takes', 'a', 'breath,\\\\nplease', 'sign', 'up.\\\\n\\\\n\\\\n\\\\n\\\\npopular', 'answered', 'questions\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nis', 'this', 'book', 'appropriate', 'for', '13-14', 'year', 'old', '8th', 'graders?', 'we', 'have', 'students', 'requesting', 'novels', 'with', 'lesbian', 'protagonists', 'and', 'unfortunately,', 'i', 'can&#39;t', 'find', 'many', 'that', 'seem', 'appropriate', 'for', 'my', 'students.', 'mild', 'cursing,', 'but', 'i', 'don&#39;t', 'want', 'it', 'to', 'be', 'focused', 'solely', 'on', 'the', 'sexual', 'identity', 'of', 'the', 'character.\\\\n\\\\n\\\\n\\\\n\\\\nlike\\\\n\\\\n\\\\n\\\\n3', 'years', 'ago\\\\n\\\\n\\\\nsee', 'all', '5', 'answers\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntaiwo', '|', 'a', 'lifestyle', 'nerd', '\\\\n\\\\n\\\\nthere&apos;s', 'not', 'a', 'lot', 'of', 'sexuality', 'in', 'the', 'book.', 'a', 'little', 'kissing', 'and', 'very', 'little', 'sex', 'but', 'that', 'aspect', 'is', 'very', 'little.', 'the', 'romance', 'is', 'actually', 'cute.', 'most', \"im\\\\xe2\\\\x80\\\\xa6morethere\\\\'s\", 'not', 'a', 'lot', 'of', 'sexuality', 'in', 'the']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "f = open('julietreviews.txt', 'r')\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "text = text.lower()\n",
    "import re\n",
    "word_bag = re.compile(r'\\W+', re.UNICODE).split(text)\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['juliet', 'takes', 'a', 'breath', 'nplease', 'sign', 'up', 'n', 'n', 'n', 'n', 'npopular', 'answered', 'questions', 'n', 'n', 'n', 'n', 'n', 'nis', 'this', 'book', 'appropriate', 'for', '13', '14', 'year', 'old', '8th', 'graders', 'we', 'have', 'students', 'requesting', 'novels', 'with', 'lesbian', 'protagonists', 'and', 'unfortunately', 'i', 'can', '39', 't', 'find', 'many', 'that', 'seem', 'appropriate', 'for', 'my', 'students', 'mild', 'cursing', 'but', 'i', 'don', '39', 't', 'want', 'it', 'to', 'be', 'focused', 'solely', 'on', 'the', 'sexual', 'identity', 'of', 'the', 'character', 'n', 'n', 'n', 'n', 'nlike', 'n', 'n', 'n', 'n3', 'years', 'ago', 'n', 'n', 'nsee', 'all', '5', 'answers', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Regular Expressions: https://docs.python.org/3/library/re.html#re.Pattern.match\n",
    "\n",
    "def preprocess_text(filename):\n",
    "    f = open(filename, 'r')\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    text = text.lower()\n",
    "    import re\n",
    "    return re.compile(r'\\W+', re.UNICODE).split(text)\n",
    "\n",
    "word_bag = preprocess_text('julietreviews.txt')\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['juliet', 'takes', 'a', 'breath', 'nplease', 'sign', 'up', 'n', 'n', 'n', 'n', 'npopular', 'answered', 'questions', 'n', 'n', 'n', 'n', 'n', 'nis', 'this', 'book', 'appropriate', 'for', '13', '14', 'year', 'old', '8th', 'graders', 'we', 'have', 'students', 'requesting', 'novels', 'with', 'lesbian', 'protagonists', 'and', 'unfortunately', 'i', 'can', '39', 't', 'find', 'many', 'that', 'seem', 'appropriate', 'for', 'my', 'students', 'mild', 'cursing', 'but', 'i', 'don', '39', 't', 'want', 'it', 'to', 'be', 'focused', 'solely', 'on', 'the', 'sexual', 'identity', 'of', 'the', 'character', 'n', 'n', 'n', 'n', 'nlike', 'n', 'n', 'n', 'n3', 'years', 'ago', 'n', 'n', 'nsee', 'all', '5', 'answers', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#box for holding the count of each word iin the order it appears\n",
    "word_freq = []\n",
    "\n",
    "#loop through every single word in our dataset\n",
    "for word in word_bag:\n",
    "    # count how many times that word appears in the the whole bag of words, then save that count at the same spot in line (same index as the word_bag - in word_freq)\n",
    "    word_freq.append(word_bag.count(word))\n",
    "#shows us the counts of each word in order\n",
    "print(\"Frequencies: \" + str(word_freq[0:100]))\n",
    "#zip the two lists, so that the pairs are connected\n",
    "print(\"Pairs: \" + str(list(zip(word_bag[0:100],word_freq[0:100]))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Frequencies: [155, 37, 526, 31, 1, 3, 68, 5927, 5927, 5927, 5927, 1, 1, 3, 5927, 5927, 5927, 5927, 5927, 1, 326, 305, 2, 192, 3, 5, 23, 15, 1, 1, 55, 74, 3, 1, 4, 167, 29, 3, 665, 1, 565, 55, 4, 221, 13, 21, 262, 4, 2, 192, 94, 3, 1, 1, 136, 565, 37, 4, 221, 18, 387, 529, 76, 3, 2, 98, 716, 4, 18, 521, 716, 20, 5927, 5927, 5927, 5927, 3, 5927, 5927, 5927, 3, 9, 5, 5927, 5927, 3, 100, 116, 1, 5927, 5927, 5927, 5927, 5927, 5927, 5927, 5927, 5927, 5927, 5927]\n",
      "Pairs: [('juliet', 155), ('takes', 37), ('a', 526), ('breath', 31), ('nplease', 1), ('sign', 3), ('up', 68), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('npopular', 1), ('answered', 1), ('questions', 3), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('nis', 1), ('this', 326), ('book', 305), ('appropriate', 2), ('for', 192), ('13', 3), ('14', 5), ('year', 23), ('old', 15), ('8th', 1), ('graders', 1), ('we', 55), ('have', 74), ('students', 3), ('requesting', 1), ('novels', 4), ('with', 167), ('lesbian', 29), ('protagonists', 3), ('and', 665), ('unfortunately', 1), ('i', 565), ('can', 55), ('39', 4), ('t', 221), ('find', 13), ('many', 21), ('that', 262), ('seem', 4), ('appropriate', 2), ('for', 192), ('my', 94), ('students', 3), ('mild', 1), ('cursing', 1), ('but', 136), ('i', 565), ('don', 37), ('39', 4), ('t', 221), ('want', 18), ('it', 387), ('to', 529), ('be', 76), ('focused', 3), ('solely', 2), ('on', 98), ('the', 716), ('sexual', 4), ('identity', 18), ('of', 521), ('the', 716), ('character', 20), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('nlike', 3), ('n', 5927), ('n', 5927), ('n', 5927), ('n3', 3), ('years', 9), ('ago', 5), ('n', 5927), ('n', 5927), ('nsee', 3), ('all', 100), ('5', 116), ('answers', 1), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927), ('n', 5927)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "a3bce285177441cdc767e3a9c4ffb6c946df65ec3625de136fb9d1815a6425f2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}