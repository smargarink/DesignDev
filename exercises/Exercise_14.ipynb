{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Fourteen: Project Design Starter\n",
    "In this exercise, you'll be planning out a complex project. You'll draw in some code, but focus on commenting to describe your project structure. The sample document below will guide you through organizing and annotating your project design. The primary components you'll include are:\n",
    "\n",
    "- Dependencies: What modules will your project need?\n",
    "- Collection: Where is your data coming from?\n",
    "- Processing: How will you format and process your data?\n",
    "- Analysis: What techniques will you use to understand your data?\n",
    "- Visualization: How will you visualize and explore your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "I plan on extracting information from Twitter using #BlerDcon. BlerDcon is a convention — the event’s name signals that it specifically caters to blerds (black nerds), BlerDCon is an inclusive space for all POC, LGBTQ+, female, and disabled fans. Pulling data from the 2021 convention, I seek to gather more information and insight into the topics dicussed around this venue and the sentiments of the participants. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "Importing modules to extract data from hastags on twitter, compile that information into a digestible list, and then use that info to create visualizations for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Config to pull credentials for Twitter API\n",
    "import configparser\n",
    "\n",
    "#Importing Twitter API\n",
    "import tweepy\n",
    "\n",
    "import datetime\n",
    "\n",
    "import csv\n",
    "\n",
    "#Importing to help extract data\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing to map out geographical locations of responses\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "#importing to plot findings in visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing for map visualization\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "#importing to assist in compliling \n",
    "import re\n",
    "\n",
    "#Importing for punctuation\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "#importing to make a wordcloud for visualizations\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#To turn work cloud into an image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "#Importing to gather sentiments from comments\n",
    "import nltk.data\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import sentiment\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Importing Pandas to handle collected Twitter data \n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection\n",
    "Collecting data from recent 2021 convention hastag #BlerDcon. Starting date from pull will begin 01-01-2021 to current time. This can be changed later to look into other year conventions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i’m always\n",
      "I want the\n",
      "The Bipart\n",
      "It’s like \n",
      "I got a fe\n",
      "RT @blushi\n",
      "Hi. So gla\n",
      "A New Jers\n",
      "Whole time\n",
      "Niggas wil\n",
      "A lot of o\n",
      "What Does \n",
      "“A man to \n",
      "There are \n",
      "Things evo\n",
      "Missing Ar\n",
      "The U.S. m\n",
      "RT @UCF_Fo\n",
      "RT @tminsb\n",
      "About me: \n"
     ]
    }
   ],
   "source": [
    "#Pulling credentials file, so Twiiter Developer account can be accessed\n",
    "CONFIG = configparser.ConfigParser()\n",
    "CONFIG.read('credentials.ini')\n",
    "\n",
    "#Tweepy\n",
    "auth = tweepy.OAuthHandler(CONFIG['DEFAULT']['consumer_key'], CONFIG['DEFAULT']['consumer_secret'])\n",
    "auth.set_access_token(CONFIG['DEFAULT']['access_token'], CONFIG['DEFAULT']['access_token_secret'])\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    #dont need to see everything\n",
    "    print(tweet.text [0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling info in from specific hashtag\n",
    "search_words = \"#BlerDCon2021\"\n",
    "date_since = \"2020-01-01\"\n",
    "tweets = tweepy.Cursor(api.search_tweets,\n",
    "              q=search_words, lang=\"en\").items(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for tweet in tweets:\n",
    "    text = tweet._json\n",
    "    print(text)\n",
    "    favourite_count = tweet.favorite_count\n",
    "    retweet_count = tweet.retweet_count\n",
    "    created_at = tweet.created_at\n",
    "    \n",
    "    line = {'text' : text, 'favourite_count' : favourite_count, 'retweet_count' : retweet_count, 'created_at' : created_at}\n",
    "    output.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "After your data has been collected or imported, store it in a format that works for your purposes. This can vary: for Twitter analysis, it might be a Pandas dataframe, while for text, you might build a document term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#using pandas to sort tweets\n",
    "tweets_sorted = [[tweet.user.screen_name, tweet.geo, tweet.user.location, tweet.text] for tweet in tweets]\n",
    "\n",
    "#caluculating coordinates of Tweets -- doesnt look like too many locations (may not use for data set)\n",
    "tdf = pd.DataFrame(data=tweets_sorted, columns=['user', 'coordinates','location', 'tweet'])\n",
    "print(tdf)\n",
    "\n",
    "#may need to look for word count instead'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BlerDcon_topics = pd.DataFrame(review_dict)\n",
    "print(BlerDcon_topics)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Think across all of the methods we've tried this semester - what combination would be most helpful for your goals? Include code sections for each method you think is important. In most cases, a combination will be most revealing: for instance, you might employ several different textual analysis frameworks on a set of documents. Use at least two distinctly different methods of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "Finally, think about the visualizations that would be most useful to sharing and exploring your data. Consider both static and dynamic approaches from the different libraries we've worked with this semester. Include at least two preliminary visualizations."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "260556d7196b2a521c66178a7d32a40a7875a519cf758c158bc134912987d078"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
