{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Fourteen: Project Design Starter\n",
    "In this exercise, you'll be planning out a complex project. You'll draw in some code, but focus on commenting to describe your project structure. The sample document below will guide you through organizing and annotating your project design. The primary components you'll include are:\n",
    "\n",
    "- Dependencies: What modules will your project need?\n",
    "- Collection: Where is your data coming from?\n",
    "- Processing: How will you format and process your data?\n",
    "- Analysis: What techniques will you use to understand your data?\n",
    "- Visualization: How will you visualize and explore your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "I plan on extracting information from Twitter using #BlerDcon. BlerDcon is a convention — the event’s name signals that it specifically caters to blerds (black nerds), BlerDCon is an inclusive space for all POC, LGBTQ+, female, and disabled fans. Pulling data from the 2021 convention, I seek to gather more information and insight into the topics dicussed around this venue and the sentiments of the participants. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "Importing modules to extract data from hastags on twitter, compile that information into a digestible list, and then use that info to create visualizations for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Importing Config to pull credentials for Twitter API\n",
    "import configparser\n",
    "\n",
    "#Importing Twitter API\n",
    "import tweepy\n",
    "\n",
    "import datetime\n",
    "\n",
    "import csv\n",
    "\n",
    "#Importing to help extract data\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing to map out geographical locations of responses\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "#importing to plot findings in visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing for map visualization\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "#importing to assist in compliling \n",
    "import re\n",
    "\n",
    "#Importing for punctuation\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "#importing to make a wordcloud for visualizations\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#To turn work cloud into an image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "#Importing to gather sentiments from comments\n",
    "import nltk.data\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import sentiment\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Importing Pandas to handle collected Twitter data \n",
    "import pandas as pd\n",
    "\n",
    "import os'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sending GET requests from the API\n",
    "import requests\n",
    "# For saving access tokens and for file management when creating and adding to the dataset\n",
    "import os\n",
    "# For dealing with json responses we receive from the API\n",
    "import json\n",
    "# For displaying the data after\n",
    "import pandas as pd\n",
    "# For saving the response data in CSV format\n",
    "import csv\n",
    "# For parsing the dates received from twitter in readable formats\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "#To add wait time between requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'public_tweets = api.home_timeline()\\nfor tweet in public_tweets:\\n    #dont need to see everything\\n    print(tweet.text [0:10])'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pulling credentials file, so Twiiter Developer account can be accessed\n",
    "CONFIG = configparser.ConfigParser()\n",
    "CONFIG.read('credentials.ini')\n",
    "\n",
    "#Tweepy\n",
    "auth = tweepy.OAuthHandler(CONFIG['DEFAULT']['consumer_key'], CONFIG['DEFAULT']['consumer_secret'])\n",
    "auth.set_access_token(CONFIG['DEFAULT']['access_token'], CONFIG['DEFAULT']['access_token_secret'])\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "'''public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    #dont need to see everything\n",
    "    print(tweet.text [0:10])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection\n",
    "Collecting data from recent 2021 convention hastag #BlerDcon. Starting date from pull will begin 01-01-2021 to current time. This can be changed later to look into other year conventions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling info in from specific hashtag\n",
    "search_words = \"#BlerDCon2021\"\n",
    "date_since = \"2020-01-01\"\n",
    "tweets = tweepy.Cursor(api.search_tweets,\n",
    "              q=search_words, lang=\"en\").items(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "After your data has been collected or imported, store it in a format that works for your purposes. This can vary: for Twitter analysis, it might be a Pandas dataframe, while for text, you might build a document term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#using pandas to sort tweets\n",
    "tweets_sorted = [[tweet.user.screen_name, tweet.geo, tweet.user.location, tweet.text] for tweet in tweets]\n",
    "\n",
    "#caluculating coordinates of Tweets -- doesnt look like too many locations (may not use for data set)\n",
    "tdf = pd.DataFrame(data=tweets_sorted, columns=['user', 'coordinates','location', 'tweet'])\n",
    "print(tdf)\n",
    "\n",
    "#may need to look for word count instead'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BlerDcon_topics = pd.DataFrame(review_dict)\n",
    "print(BlerDcon_topics)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output)\n",
    "df.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to organize CSV better then this function will work better\n",
    "\n",
    "df = pd.read_csv('output.csv')\n",
    "# Prints how pd will structure data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to read CSV another way\n",
    "f = open('output.csv', 'r')\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "#split_string\n",
    "word_bag = text.split()\n",
    "print(word_bag[0:100])\n",
    "\n",
    "#make lower case\n",
    "text = text.lower()\n",
    "word_bag = text.split()\n",
    "print(word_bag[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Would like to analyze the CSV file for common key terms and number of times a topic is mentioned. From their try to build out sentiments of users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "The goal was to create a word cloud with common topics from the hashtag and place it over the logo for the conference. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "260556d7196b2a521c66178a7d32a40a7875a519cf758c158bc134912987d078"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
