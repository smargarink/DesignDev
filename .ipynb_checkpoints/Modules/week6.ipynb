{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#sample data from: https://www.kaggle.com/gunnvant/game-of-thrones-srt\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#find a different file from kaggale (json) file that I want to use\n",
    "with open(\"season1.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "data_frame = pd.DataFrame(data)\n",
    "data_frame"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#reorganize (swap the axis) so the data makes more sense and is easier to read\n",
    "reordered = data_frame.T\n",
    "reordered"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#get bloean value for things that are lines versus empty boxes (get length in terms of diologue in each epsiode)\n",
    "reordered.notna()\n",
    "\n",
    "#how many lines of talking per each episode\n",
    "reordered.count(axis = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#make a visualization of the above\n",
    "reordered.count(axis=1).plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#make is a more readable graph by using a bar graph with specific labels - more meanigful visaulization\n",
    "reordered.count(axis=1).plot(kind='bar')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next assignment - demo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#going from source code to pandas (can use beautiful soup to scrape just about anything)\n",
    "#documented at: https://towardsdatascience.com/web-scraping-metacritic-reviews-using-beautifulsoup-63801bbe200e\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url = 'https://www.metacritic.com/game/switch/animal-crossing-new-horizons/user-reviews?page=0'\n",
    "\n",
    "#be a \"user\" so the site lets you in to scrape (sneaky)\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "response = requests.get(url, headers = user_agent)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#box to put structured data in (dictionary format to store values to hold info for each review)\n",
    "review_dict = {'name':[], 'date':[], 'rating':[], 'review':[]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#look for review_content tags since every user review has this tag\n",
    " \n",
    "#break at empty boxes \n",
    "for review in soup.find_all('div', class_='review_content'): \n",
    "    if review.find('div', class_='name') == None:\n",
    "        break \n",
    "    #find and save review - \"append\" because its adding to the data frame\n",
    "    review_dict['name'].append(review.find('div', class_='name').find('a').text)\n",
    "    review_dict['date'].append(review.find('div', class_='date').text)\n",
    "    review_dict['rating'].append(review.find('div', class_='review_grade').find_all('div')[0].text)\n",
    "    #blurb vs blurb expanded & do not display \"no review data\"\n",
    "    if review.find('span', class_='blurb blurb_expanded'): \n",
    "        review_dict['review'].append(review.find('span', class_='blurb blurb_expanded').text)\n",
    "        print(review.find('span', class_='blurb blurb_expanded').text)\n",
    "    elif review.find('div',class_='review_body').find('span') == None:\n",
    "        review_dict['review'].append('No review text.')\n",
    "        print(\"No review\")\n",
    "    else:\n",
    "        review_dict['review'].append(review.find('div',class_='review_body').find('span').text)\n",
    "        print(review.find('div',class_='review_body').find('span').text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#can we take this to a data frame? send data to panda frame\n",
    "ac_reviews = pd.DataFrame(review_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#show it in the final form?\n",
    "ac_reviews"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next class demo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#network graph (connection of things) - math! \n",
    "#edges are the connections, nodes are the things\n",
    "\n",
    "V = {1, 2, 3, 4, 5}\n",
    "E = {(1, 2), (1, 4), (2, 5), (3, 4), (4, 5)}\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(V)\n",
    "G.add_edges_from(E)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nx.draw_networkx(G, font_color=\"white\")\n",
    "plt.axis('off');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\n",
    "\n",
    "G_symmetric = nx.Graph()\n",
    "G_symmetric.add_edge('Elizabeth Bennet','Fitzwilliam Darcy')\n",
    "G_symmetric.add_edge('Elizabeth Bennet','Jane Bennet')\n",
    "G_symmetric.add_edge('Elizabeth Bennet','Georgiana Darcy')\n",
    "G_symmetric.add_edge('Elizabeth Bennet','Charles Bingley')\n",
    "G_symmetric.add_edge('Fitzwilliam Darcy','Jane Bennet')\n",
    "G_symmetric.add_edge('Fitzwilliam Darcy','Georgiana Darcy')\n",
    "G_symmetric.add_edge('Fitzwilliam Darcy','Charles Bingley')\n",
    "G_symmetric.add_edge('Charles Bingley','Jane Bennet')\n",
    "\n",
    "nx.draw_networkx(G_symmetric)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "introducing tei - how do we make sense of complex meta data? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parcer for xml - make sense of it\n",
    "import lxml.etree\n",
    "\n",
    "tree = lxml.etree.parse('Shrew.xml')\n",
    "\n",
    "print(tree)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#navigation \n",
    "print(lxml.etree.tostring(tree).decode()[0:500])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#to read tree we have to understand roots and children\n",
    "#repeats name space \"announces itself to you\"\n",
    "print(tree.getroot().tag)\n",
    "\n",
    "print(len(tree.getroot()))\n",
    "\n",
    "#looping - for every piece here \"what are you?\"\n",
    "for child in tree.getroot():\n",
    "    print(child.tag, child.attrib)\n",
    "    for nested in child:\n",
    "        print(nested.tag, nested.attrib)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#start seeing divs that coorespond to those nodes \n",
    "start = tree.getroot()[1][1]\n",
    "print(start.tag)\n",
    "for child in start:\n",
    "    print (child.tag)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#this won't work - need the namespace (as shown above)\n",
    "#save name space map first and then use it to navigate the tree\n",
    "\n",
    "print(tree.getroot().find('title'))\n",
    "\n",
    "#using a namespace map\n",
    "\n",
    "NSMAP = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "print(tree.getroot().find('.//tei:title', namespaces=NSMAP).text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def character_network(tree):\n",
    "    \"\"\"Construct a character interaction network.\n",
    "\n",
    "    Construct a character interaction network for Shakespeare texts in\n",
    "    the Folger Digital Text collection. Character interaction networks\n",
    "    are constructed on the basis of successive speaker turns in the texts,\n",
    "    and edges between speakers are created when their utterances follow\n",
    "    one another.\n",
    "\n",
    "    Arguments:\n",
    "        tree: An lxml.ElementTree instance representing one of the XML\n",
    "            files in the Folger Shakespeare collection.\n",
    "\n",
    "    Returns:\n",
    "        A character interaction network represented as a weighted,\n",
    "        undirected NetworkX Graph.\n",
    "\n",
    "    \"\"\"\n",
    "    #creating a graph\n",
    "    G = nx.Graph()\n",
    "    # extract a list of speaker turns for each scene in a play\n",
    "    for scene in tree.iterfind('.//tei:div2[@type=\"scene\"]', NSMAP):\n",
    "        speakers = scene.findall('.//tei:sp', NSMAP)\n",
    "        # iterate over the sequence of speaker turns...\n",
    "        for i in range(len(speakers) - 1):\n",
    "            # ... and extract pairs of adjacent speakers\n",
    "            try:\n",
    "                speaker_i = speakers[i].attrib['who'].split('_')[0].replace('#', '')\n",
    "                speaker_j = speakers[i + 1].attrib['who'].split('_')[0].replace('#', '')\n",
    "                # if the interaction between two speakers has already\n",
    "                # been attested, update their interaction count\n",
    "                if G.has_edge(speaker_i, speaker_j):\n",
    "                    G[speaker_i][speaker_j]['weight'] += 1\n",
    "                # else add an edge between speaker i and j to the graph\n",
    "                else:\n",
    "                    G.add_edge(speaker_i, speaker_j, weight=1)\n",
    "            except KeyError:\n",
    "                continue\n",
    "    return G"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = character_network(tree.getroot())\n",
    "print(f\"N nodes = {G.number_of_nodes()}, N edges = {G.number_of_edges()}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import collections\n",
    "\n",
    "interactions = collections.Counter()\n",
    "\n",
    "for speaker_i, speaker_j, data in G.edges(data=True):\n",
    "    interaction_count = data['weight']\n",
    "    interactions[speaker_i] += interaction_count\n",
    "    interactions[speaker_j] += interaction_count\n",
    "\n",
    "nodesizes = [interactions[speaker] * 5 for speaker in G]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create an empty figure of size 15x15\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "# Compute the positions of the nodes using the spring layout algorithm\n",
    "pos = nx.spring_layout(G, k=0.5, iterations=200)\n",
    "# Then, add the edges to the visualization\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.4)\n",
    "# Subsequently, add the weighted nodes to the visualization\n",
    "nx.draw_networkx_nodes(G, pos, node_size=nodesizes, alpha=0.4)\n",
    "# Finally, add the labels (i.e. the speaker IDs) to the visualization\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "plt.axis('off');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#save the above as a JSON file\n",
    "import json\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "with open('shrew.json', 'w') as f:\n",
    "    json.dump(json_graph.node_link_data(G), f)\n",
    "\n",
    "with open('shrew.json') as f:\n",
    "    d = json.load(f)\n",
    "\n",
    "G = json_graph.node_link_graph(d)\n",
    "print(f\"Graph with {len(G.nodes())} nodes and {len(G.edges())} edges.\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}